{
  "name": "loquacious-server",
  "version": "1.0.0",
  "scripts": {
    "compile": "tsc -b",
    "start": "ts-node -r tsconfig-paths/register src/server.ts",
    "dev": "nodemon -r tsconfig-paths/register --watch src src/server.ts",
    "migrate:create": "node-pg-migrate --tsconfig ./tsconfig.json --migration-file-language ts create",
    "migrate:up": "node-pg-migrate --tsconfig ./tsconfig.json up",
    "migrate:down": "node-pg-migrate --tsconfig ./tsconfig.json down",
    "migrate:help": "node-pg-migrate --tsconfig ./tsconfig.json help",
    "test": "mocha --experimental-loader ts-node/esm --require tsconfig-paths/register",
    "nodeversion":  "ts-node --showConfig -vv"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "description": "Server component that can connect to OpenAI or local llama.cpp server",
  "dependencies": {
    "@fal-ai/client": "^1.1.1",
    "cors": "^2.8.5",
    "dotenv": "^16.4.5",
    "elevenlabs": "^0.16.1",
    "express": "^4.21.1",
    "fluent-ffmpeg": "^2.1.3",
    "node-pg-migrate": "^6.2.2",
    "openai": "^4.67.0",
    "pg": "^8.13.1",
    "sharp": "^0.33.5",
    "socket.io": "^4.8.1",
    "undici": "^6.21.0"
  },
  "devDependencies": {
    "@swc/core": "^1.9.2",
    "@swc/helpers": "^0.5.15",
    "@types/chai": "^5.0.1",
    "@types/cors": "^2.8.17",
    "@types/express": "^4.17.21",
    "@types/fluent-ffmpeg": "^2.1.27",
    "@types/mocha": "^10.0.9",
    "@types/node": "^22.9.0",
    "@types/pg": "^8.11.10",
    "chai": "^5.1.2",
    "mocha": "^10.8.2",
    "regenerator-runtime": "^0.14.1",
    "ts-node": "^10.9.2",
    "tsconfig-paths": "^4.2.0",
    "typescript": "^5.6.3"
  },
  "optionalDependencies": {
    "bufferutil": "^4.0.8",
    "utf-8-validate": "^6.0.5"
  },
  "engines": {
    "node": ">=20",
    "pnpm": ">=9â€”"
  }
}
